{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhaledELKarazle97/AHU-Analyzer/blob/master/Facial_Landmarks_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iv9wRjqKMDNT"
      },
      "outputs": [],
      "source": [
        "# opencv 4.1.2 to read images\n",
        "import cv2\n",
        "# used for accessing url to download files\n",
        "import urllib.request as urlreq\n",
        "# used to access local directory\n",
        "import os\n",
        "# used to plot our images\n",
        "import matplotlib.pyplot as plt\n",
        "# used to change image size\n",
        "from pylab import rcParams\n",
        "import numpy as np\n",
        "import random\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from scipy.stats import norm, kurtosis\n",
        "print(cv2.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDUVXrQhy5hD"
      },
      "outputs": [],
      "source": [
        "MEAN_FGNET = []\n",
        "MEAN_UTK = []\n",
        "MEAN_GAN2 = []\n",
        "MEAN_GAN3 = []\n",
        "MEAN_ADIENCE = []\n",
        "\n",
        "\n",
        "STD_FGNET = []\n",
        "STD_UTK = []\n",
        "STD_GAN2 = []\n",
        "STD_GAN3 = []\n",
        "STD_ADIENCE = []\n",
        "\n",
        "\n",
        "def getLandmarks(pic):\n",
        "  pic = pic\n",
        "  # read image with openCV\n",
        "  image = cv2.imread(pic)\n",
        "\n",
        "  # plot image with matplotlib package\n",
        "  plt.imshow(image)\n",
        "  # convert image to RGB colour\n",
        "  image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # plot image with matplotlib package\n",
        "  plt.imshow(image_rgb)\n",
        "\n",
        "  # set dimension for cropping image\n",
        "  x, y, width, depth = 50, 200, 950, 500\n",
        "  image_cropped = cv2.resize(image_rgb,(256,256))\n",
        "\n",
        "  # create a copy of the cropped image to be used later\n",
        "  image_template = image_cropped.copy()\n",
        "\n",
        "  # convert image to Grayscale\n",
        "  image_gray = cv2.cvtColor(image_cropped, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  # remove axes and show image\n",
        "  # plt.axis(\"off\")\n",
        "  # plt.imshow(image_gray, cmap = \"gray\")\n",
        "  # save face detection algorithm's url in haarcascade_url variable\n",
        "  haarcascade_url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_alt2.xml\"\n",
        "\n",
        "  # save face detection algorithm's name as haarcascade\n",
        "  haarcascade = \"haarcascade_frontalface_alt2.xml\"\n",
        "\n",
        "  # chech if file is in working directory\n",
        "  if (haarcascade in os.listdir(os.curdir)):\n",
        "      print(\"\")\n",
        "  else:\n",
        "      # download file from url and save locally as haarcascade_frontalface_alt2.xml, < 1MB\n",
        "      urlreq.urlretrieve(haarcascade_url, haarcascade)\n",
        "      # print(\"File downloaded\")\n",
        "\n",
        "  # create an instance of the Face Detection Cascade Classifier\n",
        "  detector = cv2.CascadeClassifier(haarcascade)\n",
        "\n",
        "  # Detect faces using the haarcascade classifier on the \"grayscale image\"\n",
        "  faces = detector.detectMultiScale(image_gray)\n",
        "\n",
        "  # Print coordinates of detected faces\n",
        "  #print(\"Faces:\\n\", faces)\n",
        "\n",
        "  for face in faces:\n",
        "  #     save the coordinates in x, y, w, d variables\n",
        "      (x,y,w,d) = face\n",
        "      # Draw a white coloured rectangle around each face using the face's coordinates\n",
        "      # on the \"image_template\" with the thickness of 2 \n",
        "      cv2.rectangle(image_template,(x,y),(x+w, y+d),(255, 255, 255), 2)\n",
        "\n",
        "  #plt.axis(\"off\")\n",
        "  # plt.imshow(image_template)\n",
        "  # plt.title('Face Detection')\n",
        "  # save facial landmark detection model's url in LBFmodel_url variable\n",
        "  LBFmodel_url = \"https://github.com/kurnianggoro/GSOC2017/raw/master/data/lbfmodel.yaml\"\n",
        "\n",
        "  # save facial landmark detection model's name as LBFmodel\n",
        "  LBFmodel = \"lbfmodel.yaml\"\n",
        "\n",
        "  # check if file is in working directory\n",
        "  if (LBFmodel in os.listdir(os.curdir)):\n",
        "      print(\"\")\n",
        "  else:\n",
        "      # download picture from url and save locally as lbfmodel.yaml, < 54MB\n",
        "      urlreq.urlretrieve(LBFmodel_url, LBFmodel)\n",
        "      print(\"\")\n",
        "\n",
        "  # create an instance of the Facial landmark Detector with the model\n",
        "  landmark_detector  = cv2.face.createFacemarkLBF()\n",
        "  landmark_detector.loadModel(LBFmodel)\n",
        "\n",
        "  # Detect landmarks on \"image_gray\"\n",
        "  _, landmarks = landmark_detector.fit(image_gray, faces)\n",
        "\n",
        "  for landmark in landmarks:\n",
        "      for x,y in landmark[0]:\n",
        "      # display landmarks on \"image_cropped\"\n",
        "      # with white colour in BGR and thickness 1\n",
        "          cv2.circle(image_cropped, (int(x),int(y)),1,(255,255,255),1)\n",
        "  #plt.axis(\"off\")\n",
        "  #plt.imshow(image_cropped)\n",
        "  #plt.show()\n",
        "  arr = np.array(landmarks)\n",
        "  #print('MEAN OF LANDMARKS:',np.mean(arr))\n",
        "  #print('STD DEV OF LANDMARKS:',np.std(arr))\n",
        "  return (np.mean(arr),np.std(arr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWpM9SaHzLjz"
      },
      "outputs": [],
      "source": [
        "onlyfiles = [f for f in listdir(r'/content/drive/MyDrive/FGNET') if isfile(join(r'/content/drive/MyDrive/FGNET', f))]\n",
        "\n",
        "for file in onlyfiles[:50]:\n",
        "  # print(file)\n",
        "  mean, std = getLandmarks(r'/content/drive/MyDrive/FGNET/'+file)\n",
        "  MEAN_FGNET.append(mean)\n",
        "  STD_FGNET.append(std)\n",
        "\n",
        "\n",
        "print(MEAN_FGNET)\n",
        "print(STD_FGNET)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8qAlu3fc3Lx"
      },
      "outputs": [],
      "source": [
        "onlyfiles = [f for f in listdir(r'/content/drive/MyDrive/Adience') if isfile(join(r'/content/drive/MyDrive/Adience', f))]\n",
        "\n",
        "for file in onlyfiles[:50]:\n",
        "  # print(file)\n",
        "  try:\n",
        "    mean, std = getLandmarks(r'/content/drive/MyDrive/Adience/'+file)\n",
        "    MEAN_ADIENCE.append(mean)\n",
        "    STD_ADIENCE.append(std)\n",
        "  except:\n",
        "    print('SKIPPING')\n",
        "\n",
        "print(MEAN_ADIENCE)\n",
        "print(STD_ADIENCE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCHItZsKzT5T"
      },
      "outputs": [],
      "source": [
        "onlyfiles = [f for f in listdir(r'/content/drive/MyDrive/Gan3Images') if isfile(join(r'/content/drive/MyDrive/Gan3Images', f))]\n",
        "\n",
        "for file in onlyfiles[:50]:\n",
        "  # print(file)\n",
        "  try:\n",
        "    mean, std = getLandmarks(r'/content/drive/MyDrive/Gan3Images/'+file)\n",
        "    MEAN_GAN3.append(mean)\n",
        "    STD_GAN3.append(std)\n",
        "  except:\n",
        "    print('SKIPPING')\n",
        "\n",
        "print(MEAN_GAN3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elImL4n02EyL"
      },
      "outputs": [],
      "source": [
        "onlyfiles = [f for f in listdir(r'/content/drive/MyDrive/RealImages') if isfile(join(r'/content/drive/MyDrive/RealImages', f))]\n",
        "\n",
        "for file in onlyfiles[:50]:\n",
        "  # print(file)\n",
        "  try:\n",
        "    mean, std =  getLandmarks(r'/content/drive/MyDrive/RealImages/'+file)\n",
        "    MEAN_UTK.append(mean)\n",
        "    STD_UTK.append(std)\n",
        "  except:\n",
        "    print('SKIPPING')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeYtfFgE4axG"
      },
      "outputs": [],
      "source": [
        "onlyfiles = [f for f in listdir(r'/content/drive/MyDrive/GanImages') if isfile(join(r'/content/drive/MyDrive/GanImages', f))]\n",
        "\n",
        "for file in onlyfiles[:50]:\n",
        "  # print(file)\n",
        "  try:\n",
        "    mean, std = getLandmarks(r'/content/drive/MyDrive/GanImages/'+file)\n",
        "    MEAN_GAN2.append(mean)\n",
        "    STD_GAN2.append(std)\n",
        "  except:\n",
        "    print('SKIPPING')\n",
        "\n",
        "print(MEAN_GAN2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jvpcp74qo7HN"
      },
      "outputs": [],
      "source": [
        "print(len(MEAN_UTK))\n",
        "print(len(MEAN_FGNET))\n",
        "print(len(MEAN_GAN2))\n",
        "print(len(MEAN_GAN3))\n",
        "print(len(MEAN_ADIENCE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7latOaSP_Ewl"
      },
      "outputs": [],
      "source": [
        "print(np.multiply(MEAN_UTK[:30],STD_UTK[:30]))\n",
        "print(np.multiply(MEAN_FGNET[:30],STD_FGNET[:30]))\n",
        "print(np.multiply(MEAN_GAN2[:30],STD_GAN2[:30]))\n",
        "print(np.multiply(MEAN_GAN3[:30],STD_GAN3[:30]))\n",
        "print(np.multiply(MEAN_ADIENCE[:30],STD_ADIENCE[:30]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcTEu0TsA0AI"
      },
      "outputs": [],
      "source": [
        "\n",
        "x = 0\n",
        "x = np.arange(start=1, stop=36, step=1)\n",
        "y = np.array(np.multiply(MEAN_GAN2[:35],0.5))\n",
        "plt.scatter(x, y, label='GAN2')\n",
        "\n",
        "x = 0\n",
        "x = np.arange(start=1, stop=36, step=1)\n",
        "y = np.array(np.multiply(MEAN_GAN3[:35],0.5))\n",
        "plt.scatter(x, y, label='GAN3')\n",
        "\n",
        "x = 0\n",
        "x = np.arange(start=1, stop=36, step=1)\n",
        "y = np.array(np.multiply(MEAN_ADIENCE[:35],0.5))\n",
        "plt.scatter(x, y, label='ADIENCE')\n",
        "\n",
        "\n",
        "x = 0\n",
        "x = np.arange(start=1, stop=36, step=1)\n",
        "y = np.array(np.multiply(MEAN_FGNET[:35],0.5))\n",
        "plt.scatter(x, y, label='FGNET')\n",
        "\n",
        "\n",
        "x = 0\n",
        "x = np.arange(start=1, stop=36, step=1)\n",
        "y = np.array(np.multiply(MEAN_UTK[:35],0.5))\n",
        "plt.scatter(x, y, label='UTKFace')\n",
        "\n",
        "legend1 = plt.legend(loc=\"upper left\", title=\"Datasets\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwBuaHH-DD-o"
      },
      "outputs": [],
      "source": [
        "x = 0\n",
        "x = np.arange(start=1, stop=31, step=1)\n",
        "y = np.array(np.multiply(MEAN_GAN2[:30],STD_GAN2[:30]))\n",
        "plt.scatter(x, y, label='GAN2')\n",
        "\n",
        "x = 0\n",
        "x = np.arange(start=1, stop=31, step=1)\n",
        "y = np.array(np.multiply(MEAN_GAN3[:30],STD_GAN3[:30]))\n",
        "plt.scatter(x, y, label='GAN3')\n",
        "\n",
        "x = 0\n",
        "x = np.arange(start=1, stop=31, step=1)\n",
        "y = np.array(np.multiply(MEAN_ADIENCE[:30],STD_ADIENCE[:30]))\n",
        "plt.scatter(x, y, label='ADIENCE')\n",
        "\n",
        "x = 0\n",
        "x = np.arange(start=1, stop=31, step=1)\n",
        "y = np.array(np.multiply(MEAN_FGNET[:30],STD_FGNET[:30]))\n",
        "plt.scatter(x, y, label='FGNET')\n",
        "\n",
        "x = 0\n",
        "x = np.arange(start=1, stop=31, step=1)\n",
        "y = np.array(np.multiply(MEAN_UTK[:30],STD_UTK[:30]))\n",
        "plt.scatter(x, y, label='UTKFace')\n",
        "\n",
        "legend1 = plt.legend(loc=\"lower left\", title=\"Datasets\")\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Facial Landmarks Analysis.ipynb",
      "provenance": [],
      "private_outputs": true,
      "mount_file_id": "1duxMsl_XW7dbJfn0gBm5tFTzsSVV0KOH",
      "authorship_tag": "ABX9TyM+K4SWEmzTJgLnVNPKZaVW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}